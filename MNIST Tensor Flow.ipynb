{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as splin\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import tensorflow as tf\n",
    "import _pickle as pickle\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.linalg as splin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotProjections(projections, clist, gridsize=2):\n",
    "    xsize = 8\n",
    "    ysize = 8\n",
    "    figs, axs = plt.subplots(nrows = gridsize, ncols = gridsize, figsize=(4*xsize,4*ysize))\n",
    "    for row in range(gridsize):\n",
    "        for col in range(gridsize):\n",
    "            if col >= row:\n",
    "                if col == row:\n",
    "                    sortIndex = row+2\n",
    "                else:\n",
    "                    sortIndex = row+1\n",
    "                py = projections[:,row]\n",
    "                px = projections[:,col+1]\n",
    "                sorting = projections[:,sortIndex].argsort()\n",
    "                \n",
    "                CLIST = np.array(clist)[sorting]\n",
    "                PX = px[sorting]\n",
    "                PY = py[sorting]\n",
    "                \n",
    "                rangeX = PX.max() - PX.min()\n",
    "                centerX = (PX.max() + PX.min())/2.0\n",
    "                rangeY = PY.max() - PY.min()\n",
    "                centerY = (PY.max() + PY.min())/2.0\n",
    "                axesDist = 0.6*max(rangeX,rangeY)\n",
    "                \n",
    "                sc1 = axs[row,col].scatter(PX,PY,alpha=0.7,c=CLIST)\n",
    "                \n",
    "                subTitle = str(row+1) + ' vs. ' + str(col+2)\n",
    "                \n",
    "                axs[row,col].set_title(subTitle)\n",
    "                axs[row,col].set_xlim([centerX - axesDist, centerX + axesDist])\n",
    "                axs[row,col].set_ylim([centerY - axesDist, centerY + axesDist])\n",
    "                axs[row,col].ticklabel_format(style='sci', scilimits=(-2,2),axis='both')\n",
    "            else:\n",
    "                axs[row,col].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "        \n",
    "def saveThing(thing,file):\n",
    "    with open(file,'wb') as fil:\n",
    "        pick = pickle.Pickler(fil)\n",
    "        pick.dump(thing)\n",
    "        pick.clear_memo()\n",
    "        \n",
    "def openThing(file,py2 = False):\n",
    "    if py2:\n",
    "        with open(file,'rb') as fil:\n",
    "            u = pickle._Unpickler(fil)\n",
    "            u.encoding = 'latin1'\n",
    "            thing = u.load()\n",
    "    else:\n",
    "        with open(file,'rb') as fil:\n",
    "            thing = pickle.load(fil)\n",
    "    return thing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop,W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.132333\n",
      "step 1, training accuracy 0.141\n",
      "step 2, training accuracy 0.175667\n",
      "step 3, training accuracy 0.176667\n",
      "step 4, training accuracy 0.156667\n",
      "step 5, training accuracy 0.17\n",
      "step 6, training accuracy 0.158667\n",
      "step 7, training accuracy 0.164\n",
      "step 8, training accuracy 0.159667\n",
      "step 9, training accuracy 0.190333\n",
      "step 10, training accuracy 0.225\n",
      "step 20, training accuracy 0.587667\n",
      "step 30, training accuracy 0.774333\n",
      "step 40, training accuracy 0.828333\n",
      "step 50, training accuracy 0.869333\n",
      "step 60, training accuracy 0.892333\n",
      "step 70, training accuracy 0.896333\n",
      "step 80, training accuracy 0.917333\n",
      "step 90, training accuracy 0.924\n",
      "step 100, training accuracy 0.931333\n",
      "step 110, training accuracy 0.933\n",
      "step 120, training accuracy 0.937\n",
      "step 130, training accuracy 0.941667\n",
      "step 140, training accuracy 0.951\n",
      "step 150, training accuracy 0.946333\n",
      "step 160, training accuracy 0.956667\n",
      "step 170, training accuracy 0.954333\n",
      "step 180, training accuracy 0.957333\n",
      "step 190, training accuracy 0.964667\n",
      "step 200, training accuracy 0.961667\n",
      "step 210, training accuracy 0.962\n",
      "step 220, training accuracy 0.962333\n",
      "step 230, training accuracy 0.962667\n",
      "step 240, training accuracy 0.966667\n",
      "step 250, training accuracy 0.966\n",
      "step 260, training accuracy 0.970667\n",
      "step 270, training accuracy 0.970333\n",
      "step 280, training accuracy 0.969\n",
      "step 290, training accuracy 0.974\n",
      "step 300, training accuracy 0.966333\n",
      "step 310, training accuracy 0.972333\n",
      "step 320, training accuracy 0.975667\n",
      "step 330, training accuracy 0.974667\n",
      "step 340, training accuracy 0.970667\n",
      "step 350, training accuracy 0.975\n",
      "step 360, training accuracy 0.975333\n",
      "step 370, training accuracy 0.977\n",
      "step 380, training accuracy 0.977\n",
      "step 390, training accuracy 0.983667\n",
      "step 400, training accuracy 0.976\n",
      "step 410, training accuracy 0.977667\n",
      "step 420, training accuracy 0.978\n",
      "step 430, training accuracy 0.981333\n",
      "step 440, training accuracy 0.981667\n",
      "step 450, training accuracy 0.983\n",
      "step 460, training accuracy 0.979\n",
      "step 470, training accuracy 0.981667\n",
      "step 480, training accuracy 0.979667\n",
      "step 490, training accuracy 0.984333\n",
      "step 500, training accuracy 0.981667\n",
      "step 510, training accuracy 0.981667\n",
      "step 520, training accuracy 0.984\n",
      "step 530, training accuracy 0.981333\n",
      "step 540, training accuracy 0.984\n",
      "step 550, training accuracy 0.982333\n",
      "step 560, training accuracy 0.983667\n",
      "step 570, training accuracy 0.987333\n",
      "step 580, training accuracy 0.989667\n",
      "step 590, training accuracy 0.983\n",
      "step 600, training accuracy 0.989333\n",
      "step 610, training accuracy 0.986\n",
      "step 620, training accuracy 0.991333\n",
      "step 630, training accuracy 0.983\n",
      "step 640, training accuracy 0.982\n",
      "step 650, training accuracy 0.989333\n",
      "step 660, training accuracy 0.986333\n",
      "step 670, training accuracy 0.990667\n",
      "step 680, training accuracy 0.988333\n",
      "step 690, training accuracy 0.989\n",
      "step 700, training accuracy 0.989333\n",
      "step 710, training accuracy 0.986667\n",
      "step 720, training accuracy 0.987333\n",
      "step 730, training accuracy 0.991\n",
      "step 740, training accuracy 0.987667\n",
      "step 750, training accuracy 0.987\n",
      "step 760, training accuracy 0.988\n",
      "step 770, training accuracy 0.989667\n",
      "step 780, training accuracy 0.993\n",
      "step 790, training accuracy 0.993667\n",
      "step 800, training accuracy 0.991333\n",
      "step 810, training accuracy 0.994667\n",
      "step 820, training accuracy 0.988667\n",
      "step 830, training accuracy 0.986\n",
      "step 840, training accuracy 0.991333\n",
      "step 850, training accuracy 0.991667\n",
      "step 860, training accuracy 0.988333\n",
      "step 870, training accuracy 0.991\n",
      "step 880, training accuracy 0.991333\n",
      "step 890, training accuracy 0.990333\n",
      "step 900, training accuracy 0.991333\n",
      "step 910, training accuracy 0.991667\n",
      "step 920, training accuracy 0.992\n",
      "step 930, training accuracy 0.993333\n",
      "step 940, training accuracy 0.992\n",
      "step 950, training accuracy 0.991333\n",
      "step 960, training accuracy 0.992667\n",
      "step 970, training accuracy 0.992\n",
      "step 980, training accuracy 0.992\n",
      "step 990, training accuracy 0.991\n",
      "step 1000, training accuracy 0.994667\n",
      "step 1010, training accuracy 0.994333\n",
      "step 1020, training accuracy 0.991667\n",
      "step 1030, training accuracy 0.991333\n",
      "step 1040, training accuracy 0.992333\n",
      "step 1050, training accuracy 0.993333\n",
      "step 1060, training accuracy 0.995333\n",
      "step 1070, training accuracy 0.992\n",
      "step 1080, training accuracy 0.995333\n",
      "step 1090, training accuracy 0.993\n",
      "step 1100, training accuracy 0.994667\n",
      "step 1110, training accuracy 0.994333\n",
      "step 1120, training accuracy 0.993333\n",
      "step 1130, training accuracy 0.996\n",
      "step 1140, training accuracy 0.996\n",
      "step 1150, training accuracy 0.993333\n",
      "step 1160, training accuracy 0.997\n",
      "step 1170, training accuracy 0.992\n",
      "step 1180, training accuracy 0.992667\n",
      "step 1190, training accuracy 0.992333\n",
      "step 1200, training accuracy 0.997\n",
      "step 1210, training accuracy 0.993667\n",
      "step 1220, training accuracy 0.993667\n",
      "step 1230, training accuracy 0.994\n",
      "step 1240, training accuracy 0.993333\n",
      "step 1250, training accuracy 0.993667\n",
      "step 1260, training accuracy 0.995\n",
      "step 1270, training accuracy 0.993667\n",
      "step 1280, training accuracy 0.994667\n",
      "step 1290, training accuracy 0.997\n",
      "step 1300, training accuracy 0.994333\n",
      "step 1310, training accuracy 0.997667\n",
      "step 1320, training accuracy 0.995\n",
      "step 1330, training accuracy 0.997333\n",
      "step 1340, training accuracy 0.997\n",
      "step 1350, training accuracy 0.996\n",
      "step 1360, training accuracy 0.994333\n",
      "step 1370, training accuracy 0.996667\n",
      "step 1380, training accuracy 0.996333\n",
      "step 1390, training accuracy 0.994667\n",
      "step 1400, training accuracy 0.997\n",
      "step 1410, training accuracy 0.994\n",
      "step 1420, training accuracy 0.997333\n",
      "step 1430, training accuracy 0.997\n",
      "step 1440, training accuracy 0.996333\n",
      "step 1450, training accuracy 0.997333\n",
      "step 1460, training accuracy 0.994\n",
      "step 1470, training accuracy 0.996667\n",
      "step 1480, training accuracy 0.996667\n",
      "step 1490, training accuracy 0.997667\n",
      "step 1500, training accuracy 0.995333\n",
      "step 1510, training accuracy 0.996333\n",
      "step 1520, training accuracy 0.998333\n",
      "step 1530, training accuracy 0.996333\n",
      "step 1540, training accuracy 0.996667\n",
      "step 1550, training accuracy 0.996667\n",
      "step 1560, training accuracy 0.996333\n",
      "step 1570, training accuracy 0.998\n",
      "step 1580, training accuracy 0.994667\n",
      "step 1590, training accuracy 0.998\n",
      "step 1600, training accuracy 0.998333\n",
      "step 1610, training accuracy 0.995667\n",
      "step 1620, training accuracy 0.997\n",
      "step 1630, training accuracy 0.998333\n",
      "step 1640, training accuracy 0.996333\n",
      "step 1650, training accuracy 0.999333\n",
      "step 1660, training accuracy 0.997\n",
      "step 1670, training accuracy 0.996667\n",
      "step 1680, training accuracy 0.997667\n",
      "step 1690, training accuracy 0.998\n",
      "step 1700, training accuracy 0.997\n",
      "step 1710, training accuracy 0.998333\n",
      "step 1720, training accuracy 0.998667\n",
      "step 1730, training accuracy 0.998\n",
      "step 1740, training accuracy 0.998333\n",
      "step 1750, training accuracy 0.998\n",
      "step 1760, training accuracy 0.998\n",
      "step 1770, training accuracy 0.997333\n",
      "step 1780, training accuracy 0.997333\n",
      "step 1790, training accuracy 0.999333\n",
      "step 1800, training accuracy 0.998\n",
      "step 1810, training accuracy 0.995333\n",
      "step 1820, training accuracy 0.996\n",
      "step 1830, training accuracy 0.998667\n",
      "step 1840, training accuracy 0.998333\n",
      "step 1850, training accuracy 0.999\n",
      "step 1860, training accuracy 0.999\n",
      "step 1870, training accuracy 0.999\n",
      "step 1880, training accuracy 0.998333\n",
      "step 1890, training accuracy 0.995333\n",
      "step 1900, training accuracy 0.997667\n",
      "step 1910, training accuracy 0.997667\n",
      "step 1920, training accuracy 0.996333\n",
      "step 1930, training accuracy 0.996333\n",
      "step 1940, training accuracy 0.999333\n",
      "step 1950, training accuracy 0.998333\n",
      "step 1960, training accuracy 0.998333\n",
      "step 1970, training accuracy 0.999667\n",
      "step 1980, training accuracy 0.999333\n",
      "step 1990, training accuracy 0.998333\n",
      "test accuracy 0.9907\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "accuraciesTraining = []\n",
    "accuraciesTest = []\n",
    "allProbs = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    #test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "    #print('Initializing, training accuracy %g' % (train_accuracy))\n",
    "    #accuraciesTraining.append([-1, train_accuracy])\n",
    "    #accuraciesTest.append([-1, test_accuracy])\n",
    "    #probs_estimators = y_conv.eval(feed_dict={x: mnist.test.images, keep_prob:1.0},session=sess)\n",
    "    #allProbs.append(np.array([[np.exp(x)/sum([np.exp(y) for y in prob]) for x in prob] for prob in probs_estimators]))\n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(3000)\n",
    "        if (i % 10 == 0) or (i < 10):\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            accuraciesTraining.append([i, train_accuracy])\n",
    "            accuraciesTest.append([i, test_accuracy])\n",
    "            if (i % 100 == 0) or (i < 100):\n",
    "                probs_estimators = y_conv.eval(feed_dict={x: mnist.test.images, keep_prob:1.0},session=sess)\n",
    "                allProbs.append(np.array([[np.exp(x)/sum([np.exp(y) for y in prob]) for x in prob] for prob in probs_estimators]))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    probs_estimators = y_conv.eval(feed_dict={x: mnist.test.images, keep_prob:1.0},session=sess)\n",
    "    allProbs.append(np.array([[np.exp(x)/sum([np.exp(y) for y in prob]) for x in prob] for prob in probs_estimators]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveThing(accuraciesTraining,'accuraciesTraining.pckl')\n",
    "saveThing(accuraciesTest,'accuraciesTest.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveThing(allProbs,'allProbs.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(allProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAACsCAYAAAAt1Uu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8VFX6+PHPMy0z6Y0USgABpSNVRFRcwF6wreiisIoI\nNta6uKvuz/VrXTvqoq6KHRd1V1dcVHCRKiiKgiBKCxAgQEJ6m3J+f8wQQwhkQpKZDHner9d9zdxz\n2zPJYXhy7jnnijEGpZRSSikVGSzhDkAppZRSSgVPkzellFJKqQiiyZtSSimlVATR5E0ppZRSKoJo\n8qaUUkopFUE0eVNKKaWUiiCavCmllFJKRZCQJm8icoqIfCQiOSJiRGRCEMf0EZEvRaQ8cNy9IiIh\nCFcppZRSqsUJdctbLLAGmAqU17eziMQDnwO5wODAcXcAtzZjjEoppZRSLZaE6wkLIlIC3GiMmXmY\nfaYAjwDpxpjyQNndwBSgvdHHQyillFKqlWnpfd5OBBbtT9wCPgXaAp3CEpFSSimlVBjZwh1APTKA\n7bXKcmts21xzg4hMAiYBuFyugR06dGjW4LZt24YxhqysrGa9jmrdfD4fFktL/zvrYNu2bQOguf8d\nqqYRqfVMRZZIrGeh+i77+eef9xpj2gSzb0tP3hrEGPMi8CLAoEGDzDfffNOs1xsxYgQFBQWsWrWq\nWa+jWrcFCxYwYsSIcIfRYPtjXrBgQVjjUMGJ1HqmIksk1rNQfZeJSHaw+7b09HcXkF6rLL3GNqWU\nUkqpVqWlJ2/LgJNFxFmjbDSwA9gSloiUUkoppcIo1PO8xYrI8SJyfODaWYH1rMD2h0Rkfo1D3gbK\ngJki0ltELgKmAU/oSFOllFJKtUahbnkbBHwXWFzAfYH3fw1szwS67N/ZGFOIv6WtLfAN8BzwOPBE\n6EJWSimllGo5QjpgwRizADjk0xGMMRPqKFsNnNJ8USmllFJKRY6W3udNKaWUUkrVoMmbUkoppVQE\nqTd5ExG7iDwqIh1DEZBSSimllDq0epM3Y4wbuJ7D9FVTSimllFKhEext00+B3zRnIEoppZRSqn7B\njjadDzwoIn2BlUBpzY3GmA+aOjCllFJKKXWwYJO3ZwOvN9exzQDWpgknwuz6gTh3FcwYHu5IGs4a\nBdEpgSW5xvtaiysRLK3z16uUUkq1REElb8YYHZVah4JKAWNnyR4XIiAiWAKvAlhEDii3BMp/3a/G\nPvx6bPU56tlugYOue9A5DojDfx4A3GVQvBNyf4TyfP96nQRcSbWSutrrKQcmglEJYNEqo5RSSjWH\nkE7Se7QpiDmG8spKZnV9FI/Xh9tr8Ph8uPe/9/rw+Axur8Ht9dXaZ3/Zr+uhYLcKNouFBJedjinR\ndMyKpmNKDMckWDgmppJ2UWXEeguhLB/K8g5eCrJhx7f+996qui8i1gNb8+IyIb0npPeG9F4Q386f\nSSqllFKqwYJO3kTkHOCPQE/8t0rXAo8YYz5ppthavE6pMRQUuJl+ef9Gn8sYg8dn8HgNbl8gqfP6\nqKqV4B2cGP667vYFyr0mcFwdyWNgn7zSKrbmlfG/9XvYU7z9gFiSYxx0TMmkU0pXspKj6dTWn+B1\nTI4mOcaBiIAxUFVaI7E7RLJXlg/blsOa9369gDPh10QuvZf/fVoPcMQ0+udYF7fXx/Z95RRXuMlI\ncNImNsr/GZqIz2eqW0APYgzs2wK7fgCvO9D8aam1WMFq8ye1CR0gKrbJYlNKKXX0CSp5E5GJwPPA\nW8BrgeKTgX+JyBRjzCvNFF+rISLYrYLdCq4QdyEsrfSQnVfG1vxStuSVkZ1XSnZeGSs25/PvVTmY\nGo2CcVE2OqZG0zE5ho4p0XRKiSErpSOd0nqSFheFxXKIpKiiEHLXQu4a/63a3B9h1dtQVRLYQSC5\n86/J3P7ELrFTULdgfT7DjsJytuwtY/PeEjYHXrfklbEtvwyP79cP4bBZaJvgpF2Si7YJLv9roov2\nif7XzEQnUbZffwcllR52FJSTs6+c7QXl1e9zAu9ziyqwWSzEu+y0cXoZaNtMP37mOM9PHFOxlljP\nvob9QqJT/ElcYhYkZtF2rweKu0NcRsPOo5RS6qgUbMvbH4FbjTHP1ih7WURWAtMATd4iWEyUjZ5t\n4+nZNv6gbRVuL9v3lVcndNl5/gRv7c4iPv1x1wFJkdNuISvZ30rXKSWarMBrm7goLGLB4uoNnfpg\n6Rzoj2d82Iu3E5W3FnveOhx712Lf+SPWdR8j+M9r7NF4Unvga9MLb1pPKhOOYWeJjx2FVeQUVbG9\noDLwWkW5V/AheLFgt9lpmxTLiakxXHJsAu1TYol32ckrKGJvQSH5hXnsKyqmaFcxu8rKWE0VUbiJ\nwo1DPKRE+Uhw+Ciq8FHu9uFDAosFEaF9dBS9XA4Sk6NIbGchtXQDGUU/kFGyASs+ALZJW/5n+rLC\nfQzf+bpQhpNYh4VYh4W4KCtxDvGvR1moKC8nd/tGOtvyGBFTTi9HIVG718Evn3GspwKeeAm6jYb+\n46DbGWBzhKZyKKWUanGCTd6ygLl1lP8XeKzpwlEtjdNupWtaLF3TDr6V5/H62FFQQfb+Fru9pWTn\n+xO8hT/vodLjC/YqQP/AAi4qOFa2092yje6erfTI2Ur3He+TKK8TDSThv3d/ABsH1+aiwLKlnsvX\nlQf5gIrAe3sd26sCS+H+fWKg3QDocB60HwLtB9MhJoUOwDk+Q7nbi9NuxXqolklg/a5i/r5gA5f+\nsBOrCBcPbM/kyzuTu/zfDInaCN+/Az/PhehU6DcWjv+dvy+hUkqpViXY5G0rMBrYUKv8dCC7SSNS\nEcNmtZCVEk1WSjQndztwm89n2F1cyZa8UvJKqjAYjAFf4B6sz+xf9/f3MwRe95cxCJ+/kPUGfvL5\ncFbsJqkqh8xYGxlxdlKibf5WLuMFnxd8HjA+//v9ZdXbvP7A7E6wOcEW5X+1Og5cr351gtUOGH+/\nNeOr8Vpj2b89LtPfb60OFosQE1X/P7XjMuJ4amx/bh19HC8s3Mjsldt59+utDMlI5dFxF5F12p9h\n4xfw3Ruw/AVY9iwcdw6c9zTEtjni36NSSqnIEmzy9hgwXUQGAEsDZScBVwI3NUdgKrJZLEJGgpOM\nBGcTnvWYJjxXy5WVEs0DF/Zh6shuvLxkMzMXb2LUk18y+ZRjmDJiJK5jT4fSPFj5Knz5KDw/FM6f\nDt3PDnfoSimlQiCoybiMMS8AlwE98CdyjwHdgd8aY15svvCUar3S4p3cdVYPHj7ZxVm9M3jmiw2M\neuJL5q7ZiYlOhlNuh+u+hPhMmHU5fHgjVBaHO2yllFLNrN7kTURsInI2sNAYM9wYkxJYhhtjPgxB\njEq1aklOC0+P7c+7k4YS57Qx+c1vueqVFWzYXeKfYmXiFzD8Vlj1Fvz9JMheFu6QlVJKNaN6kzdj\njAf4AIhr/nCUUodywjEpfHzTcO47vxffbyvgzKcW8vcFGzFWO4z6C0wITLn46lnw9cvhDVYppVSz\nCfYZRt8DXZszEKVU/WxWC+OHdeJ/t4/gjF4ZPDL3J+77z1p8PgMdT4QpS+DYM2DOrfDt6+EOVyml\nVDMIdsDC/wMeF5G/ACuB0pobjTH5TRyXUuowUmKjmH55fzISnLy8eDP5pVU8dmk/HFFx8NvXYdYV\n8NHNYLHD8ZeHO1yllFJNKNjkbU7g9QOg5kM4JbAe2kcCKKWwWIS7z+lBamwUj8z9iYJyNzPGDSDa\nEQWXvQnvjIUPr/dPedLnknCHq5RSqokEm7yd1qxRKKWOiIgwZUQXkmPs3PXBaq54aTmvThhMUowL\nxr4Db10KH0wCiw16jQl3uEoppZpAvcmbiNiBc4DnjDE6Ia9SLdBlg7NIjHZw0zvfcekLy3j96iG0\nTYyGK96FNy+G96/xt8B1PyfcoSqllGqkYEabuoHr8d8iVUq1UGf0yuD1q4eQW1jBxX9fyobdxRAV\nC7+bDZnHwz/Hw8+fhTtMpZRSjRTsaNNPgd80ZyBKqcYbekwKs64bittruGTGMr7bug+c8TDuff9z\nUN8d53/EllJKqYgVbPI2H3hQRJ4SkStF5KKaS3MGqJRqmF5tE3h/yokkuOxc8dJyvvx5D7gS4cp/\nQ+qx8M7lsHlhuMNUSil1hIJN3p4F0oCbgdeA92oss5snNKXUkeqYEsPsySfSOTWGa2Z+zYerciA6\nGa76NyR1hrcvg+yl9Z9IKaVUixPss00th1l0mhClWqC0OCezrhvKwI5JTJ21ileXbIaYVBj/ESS0\n949E3bYi3GEqpZRqoGBb3pRSESjeaee1q4dwes907vvPWh7/bD0mpg1c9RHEpvlHouZ8G+4wlVJK\nNcBhkzcRWSoiiTXWHxKR5BrrqSKytTkDVEo1jtNu5fnfDWDs4A5M/2IDf/rXGryxGTD+P+BKgjfG\nwM7vwx2mUkqpINXX8jYUcNRYvwFIrLFuBdo1dVBKqaZls1p46KI+3HBaF95ZsZUb3vqWiuhMfwLn\niIPXx0Duj+EOUymlVBAaettU53pTKkKJCHec0Z17z+3J3B93MeHVFRS72sKE/4AtCl47H3b/FO4w\nlVJK1UP7vCnVylw9vDNPXXY832zZx9gXv2KPvZ2/Bc5ihdfPh70bwh2iUkqpw6gveTMc+CB66lhX\nSkWYMf3b8Y/xg9i0p5RLZixlq7TzD2LweeG18yB/U7hDVEopdQj1JW8CvCkiH4nIR4ATeKnG+uvN\nHqFSqlmMOC6Nt649gcJyNxfPWMo6b1v/NCKeCv8t1AIdi6SUUi1Rfcnba8AOIC+wvAlsq7G+A03g\nlIpYA7KSmH3didgswm9fWMby0gz/RL6VRTDzXCjMCXeISimlarEdbqMx5vehCkQpFR7d0uN4b8ow\nrnx5OVe+soJnL+/P6Vf+yz8C9bXzYMIciM8Md5hKKaUCdMCCUop2iS7emzyMHpnxTH5zJf/ckeZ/\nmH1Jrn8QQ8nucIeolFIqQJM3pRQAyTEO3p54Aid1TeXO939gxqYUzBX/hMLt/j5wpXvDHaJSSik0\neVNK1RATZePl8YM5r19bHv7vTzz4YxK+se/Avs3+26hl+eEOUSmlWj1N3pRSB3DYLDx92fGMP7Ej\nLy3azO3fJOL57Vuwdz28cSGUF4Q7RKWUatWCSt5EJEtEDnq6gvhlNX1YSqlwsliE/3d+L24bfSwf\nfJfDtUviqbz4df8jtN68GCqKwh2iUkq1WsG2vG0G2tRRnhzYppQ6yogIN43sxgMX9mbBz3u44ssE\nSi54GXaugrd/C5Ul4Q5RKaVapWCTN6HuJyvEAhVNF45SqqX53Qkdef6KAazeXshFXySy76wZsG0F\nvDMWqsrCHZ5SSrU6h03eROQZEXkGf+L20P71wPIc8B6wqiEXFJHrRWSziFSIyEoROfkw+3YSEVPH\ncmZDrqmUapyz+mQy8+rB7Cio4Nz5KeSOehqyl8Csy8Gtf78ppVQo1dfy1iewCNCjxnofoCvwLTAh\n2IuJyGXA08CDQH9gKfDfIPrNnQlk1li+CPaaSqmmMaxLKrMmDaXC7eWsLzLYdvLfYNOX8O448FSG\nOzyllGo1Dpu8GWNOM8achv8xWWftXw8sZxhjrjPG/NKA690KzDTGvGSMWWeMuQnYCUyp57g8Y8yu\nGktVA66plGoivdsl8N6UYUQ7rJy5oD2/nPAAbPgc/jkePPrPUimlQiGoPm/GmN8bYxo1vExEHMBA\n4LNamz4DhtVz+AcisltElojIJY2JQynVOJ1TY3h/yjA6JEdz9uLOrO53D/z8X3j/avC6wx2eUkod\n9Q77bNP9RMQJTAVGAmnUSvqMMX2DOE0qYAVya5XnAqMOcUwJcDuwBPAA5wPvish4Y8ybdcQ5CZgE\nkJ6ezoIFC4II68gVFBTg9Xqb/TqqdSspKWmRdeymXoanvxXOX96D59pN4Ox1M8l94UJ+6n4LxmKl\noMA/H1xLjF0drKXWM3V0icR61hK/y4JK3oDngQuB2fj7qdU18rTJGWP2Ao/XKPpGRFKAO4GDkjdj\nzIvAiwCDBg0yI0aMOOS5i4qK2L17N273kbcUPPnkkxhjSE9PP+JzqJbDbreTlpZGfHx8uEM5wIIF\nCzhcXQ6nkSO83Pj2t1y/7nRePy6eU7KfIT2jHYx5nsTERIAWG7s6UEuuZ+roEYn1rCV+lwWbvI0B\nLjXGzGvEtfYCXqB2ppMO7GrAeVYAVzciDoqKisjNzaVdu3a4XC7qmH84KBaLBY/HQ48ePRoTjmoB\njDGUl5eTk5MD0OISuJbKabcyY9xApn2wmqtWDuUfnSoY9cOLYA32q0UppVRDBTvPWxmwrTEXCgwy\nWAmMrrVpNP7WvGAdj3+QwxHbvXs37dq1Izo6+ogTN3V0ERGio6Np164du3fvDnc4EcVmtfC3S/py\n3anHMHHLCD5Jvgq+exPyNoQ7NKWUOioF++fxo8CtIjLZGNOYW6ZPAG+IyAr8/dgmA22BGQAi8hAw\nxBgzMrA+HnAD3wE+4DzgBuCPjYgBt9uNy+VqzCnUUcrlcjXqVnprJSLcdVYPUmIcXP+J4Zk2lVD8\nCogFjAH9I0kppZpMsMnbaOBk4EwRWYs/oapmjDk/mJMYY94N9Fm7G/98bWuAs40x2YFdMoEutQ67\nG+iI/5brz8DVdQ1WaChtcVN10XrROJNO6UJyTBS3vC+4LB+RWrQDPrsbTv8/TeCUUqqJBJu87QX+\n1RQXNMY8j38ARF3bJtRafw3/HHNKqQhxycD2JEXbOe+tNLAYWPYsWB0w8l5N4JRSqgkElbwZY37f\n3IGo8Bo7diwej4f33nsv6GOGDh3K8OHDeeyxx5oxMhWJRvZIp0dmPOt3wQeW47ho8RNgi4IR08Id\nmlJKRbxgBywAICKDROQyEYkJrMeIiA4rCwEROewyYcKERp3/hRde4B//+EeDjvnkk0/4y1/+0qjr\nBqO4uJg777yTLl264HQ6adOmDSeffHKDEs2ffvoJEWHNmjXNGKmqKc5po2fbBB61Xsu/GAELHoKF\nmugrpVRjBTtJbzrwITAE/xxv3YBN+AcgVOCfwFc1o507fx1g+/HHH3PttdceUHaoARhutxu73V7v\n+RMSEhocU3JycoOPORLXXHMN33//PdOnT6dnz57k5+ezbNky8vLyQnJ9deSiHVbemDKcCS9bsRS7\nueCL+zFWB3LSzeEOTSmlIlawLW9P4n8SQgr+aUP2mw2c3tRBqYNlZGRUL/snDKxZlpCQUN26NHv2\nbE499VScTievvfYaubm5XHbZZdXTo/Tu3Zu33nrrgPOPHTuWSy759cljQ4cO5ZZbbuGOO+4gOTmZ\njIwM7rrrLmoONh46dCi33377ATE+8sgjXH311cTFxdGhQweeeeaZA66zdu1aTjrpJJxOJ7169WL+\n/PnYbDZmzZpV5+c2xvDxxx9zzz33cPbZZ9OpUycGDBjADTfcwHXXXVe9n8/n44EHHqBz5864XC76\n9u3LP//5TwAqKiqq5+Lr06cPIsKZZ555JL8GdQQ6JEfz/g0n82Gne/jYOxT5/B7ci57xj0JVSinV\nYMEmbyOBPxtj9tUq3whkNW1IqrGmTZvGLbfcwrp16zj77LMpLy9n6NChzJkzhzVr1jBlyhTGjx/P\n4sWLD3ueV155hYSEBJYvX87jjz/Oo48+yr///e/DHvPYY48xZMgQvvvuO6ZOncrUqVP59ttvAfB4\nPFxwwQXExcWxYsUKXnjhBe666y58Pt8hzycipKWl8cknn1BcXHzI/e644w7efvttXnjhBdauXctt\nt93G+PHjmTdvHk6nk0WLFgH+2b137tzJO++8c9jPoZpWYrSDf0wYyqaTn+S/3iHY599DyaxroKo0\n3KEppVTECba/mguoqqO8Df7bphHvvv/8yNodRQ06pry8DGMM0Ysbdtx+PdvG85fzeh3RsYdz6623\nMmbMmAPKbrnllur3N9xwA59//jmzZs1i+PDhhzzPgAEDuPvuuwHo1q0bM2bMYP78+Vx44YWHPObc\nc89l8uTJANx+++08/fTTfPHFFwwYMIA5c+aQnZ3NkiVLSEtLA+Dhhx9m5MiRh/08L7/8MldeeSXJ\nycn069ePYcOGceGFF3LaaacB/ufOTZ8+nSVLljB48GAAOnfuzLJly3j++ecZNWoUqampAKSkpJCR\nkXHY66nmYbEIN5/ek/91eJ3n372XyetnU/LsD8Re+Ra0OS7c4SmlVMQItuVtITChxroRESv+yXLn\nN3VQqnEGDRp0wLrH4+G+++6jT58+JCcnExsby5w5c9i6dethz9O3b98D1tu2bVvv0wcOd8xPP/1E\np06dqhM3gBNOOKHezzNy5Eiys7OZN28eF198MT/++CO/+c1vmDrV39Vy9erVuN1uTjvtNGJjY6uX\nV199lY0bN9Z7fhVap/XI5Lybn+aeuPupKMyl6u+n4vthdrjDUkqpiBFsy9udwJciMhiIwv+w+F5A\nAnBSM8UWUkfSArZ+/Xo8Hg+9ejV961ljxMTEHLD+wAMP8Nxzz/HUU0/Rq1cvYmJiuO2226isrDzs\neWoPdBARvF5vg4853G3RYNntdk499VROPfVU7rrrLu6++24eeOABpk2bVn3+uXPnHtSq5nA4Gn1t\n1fQ6JEdzz83X8+jsHpz1010M/mAiFZuW4Dz3Ef+UIkoppQ4p2Hne1opIH2AKUAk48Q9WeM4Y06jn\njKrmt3jxYi688EKuuOIKwN+5/+eff6Zjx44hjaN79+5kZ2ezZ88e2rRpA8CKFSuO6Fw9e/YEoLS0\nlD59+mCz2di2bdshbwPvT+LqSz5V6DjtVu65fCSzvprF95/cy8RVr1K2fSXRv3sTkkJbN5VSKpIE\nPUebMWYX0PyTeqkmd+yxxzJnzhyWLVtGYmIiTzzxBDt27Ah58nbOOeeQlZXF+PHjefjhhykuLmba\ntGnVc9UdyvDhw5kwYQIDBw4kKSmJNWvWcO+999KnTx+6dOmCiFQPjnC73Zx00kkUFRWxdOlSXC4X\nV199NZmZmTgcDubOnUtmZiZOp5P4+PgQfnpVFxHh8hO78H3755j2Wi/+tGc6Vc8Nx3Hpi3DcWeEO\nTymlWqSg+ryJyI0i8rs6yseJyPVNH5ZqSvfddx99+/Zl9OjRjBgxgrS0tAOmBQkVm83Ghx9+SEFB\nAYMHD2bixIncc889ADidzkMed/rpp/PKK68watQounfvzk033cSoUaOYO3duddL36KOPMm3aNB58\n8EF69OjBGWecwUcffUTnzp0B/zx4Tz75JM8++yyZmZn89re/bf4PrILWr0Mid/zhNu7NfJ6fq5Lh\nnbF4Pr0XvJ5wh6aUUi2OmCDmWhKRDcB4Y8ySWuXDgVeNMd2aKb4jNmjQIPPNN9/UuW3dunXV8341\nRkvt8xZJli9fztChQ1mzZk2L+Tk2Vf1oKgsWLGDEiBHhDqPB9se8YMGCoI/x+gxPzf2BjKX38Tvb\nfCrbDSVq7GsQpyOEm1uk1jMVWSKxnh3Jd9mREJGVxphB9e8Z/GjT9kBOHeXbA9uUCsrs2bOZN28e\nW7ZsYf78+UycOJEhQ4a0mMRNhZfVItx2dj/aXP48d5kb8eV8R9VzJ8HmheEOTSmlWoxgk7ddwPF1\nlA8A9jZdOOpoV1hYyOTJk+nevTtXXXUV/fv3Z86cOeEOS7Uwp/fKYNJNf2Jq7ONsLXPge+0CfF/+\nDZpg5LJSSkW6YAcsvA08IyKlwIJA2WnAU8BbhzpIqdomTpzIxIkTwx2GigCdU2N46ubL+ct7xzB8\n3f9xwf/+D3f2V9gveQmiQ/NcXaWUaomCbXn7C7AE+BT/s03LgP8CS4F7mic0pVRrF+2w8ejlw9h3\nxnPc67kas2kB7ueHw/a6+7MqpVRrEFTyZoxxG2MuB44Frggs3Y0xY40x7uYMUCnVuokIE4Yfw/kT\n7+Fa6wPkFlfhe/kMWP6CPtxeKdUq1Zu8iYhdRHaJSC9jzAZjzOzA8ksoAlRKKYBBnZL52x8mcE/G\n88z39IX/3on3nxOg4sieLayUUpGq3uQt0LLmBvRPXKVUWKXFOXlx0iiWD5nOQ+7LYd1HeGacCrk/\nhjs0pZQKmWD7vE0H7hKRoJ/IoJRSzcFutXD3eb3pc9m9TPDdw76CfXhf/A18p2OnlFKtQ7DJ2MnA\nqUCOiKwBSmtuNMac39SBKaXU4Zzbty3HpV/L5NeP4fbiRzjxw+sx2UuRcx4Duyvc4SmlVLMJtuVt\nL/A+8AmwFcirtSilVMh1S49j5k3n8Ea3p5nuGYOsehPvS6Mgb2O4Q1NKqWYT7GjT3x9uae4gFdUP\nbz/UMmHChEZf46effkJEWLNmTb37zp8/n9NOO42UlBSio6Pp2rUrV155JWVlZUFfb+zYsWF5xqo6\nusQ57Tw3bjBRp9/L7913Upy7hYrnhvP9R89SUloS7vCUUqrJNagPm4gMAroAHxtjSkUkBqg0xujT\no5vZzp07q99//PHHXHvttQeUuVyhu020atUqzj77bP7whz8wffp0XC4XGzZs4F//+hdut84co0JP\nRJh0ShcGdbqe5xcP5ryf/0S/b/9M4coH+V/caXj6XEb/YaeTGucMd6hKKdVoQbW8iUi6iHwFrMD/\ntIX0wKYngMebKTZVQ0ZGRvWSmJh4UFlCQgIA2dnZXHrppSQmJpKcnMz555/P5s2bq8+zefNmzj33\nXJKSkoiJiaFnz5588MEHVFRUVD+MvU+fPogIZ555Zp2xzJ07lw4dOvDII4/Qu3dvunTpwhlnnMGM\nGTOq4wBYvXo1Z555JrGxsaSnpzNu3Dj27NkDwLRp03j33Xd5//33q1sPv/rqq2b52anWY0BWEn+6\n4nR63v0V60a9TnbKyZxY8hmjl11J8d/6Meuxm5j12WK25gXfQqyUUi1NsH3engRygRT8T1fYbzZw\nelMHpY5McXExI0aMICkpiUWLFrFkyRISExMZPXo0lZWVAEyaNAljDAsXLmT16tU89thjxMfH43Q6\nWbRoEQALFixg586dvPPOO3VeJyMjgx07drB48eJDxrJt2zZOOeUUBg8ezMqVK/n000/Zu3cvF198\nMQB3332uM2bBAAAXS0lEQVQ3F1xwAeeeey47d+5k586dDBw4sIl/Iqq1stps9Bh+AX1vfpeoaRvJ\nOfUxbIntGFvyOmOXnsP2p0by2KN/4dm5q/hxRyFGJ/tVSkWQYG+bjgRGGmP2iUjN8o1AVpNHFQ7/\nnQa7VjfokA7lZf4v/RUxR3bNjD5w1sNHdmwd3njjDWJiYnjxxRery15++WWSk5P59NNPOf/888nO\nzuaaa66hT58+ABxzzDHV+6ampgKQkpJCRkbGIa8zbtw4Pv/8c04++WTS09M54YQT+M1vfsO4ceNI\nSUkBYPr06QwbNoz777+/+riZM2eSmZnJDz/8QN++fXE6nXg8nsNeS6nGEmc87U67Fk67FvZlU/DV\nG/T6YRbDyp6idNnfmbtkCC+4RpHaexRn9M5kUKdkrBap/8RKKRUmwba8uYCqOsrbABVNF45qjJUr\nV/LTTz8RGxtbvSQlJVFaWsrGjf7Rd3/4wx+4++67Oemkk7j33ntZtWpVg69js9l466232LZtG48+\n+iht27blwQcfpHv37vz888/VsXz++ecHxNK1a1eA6liUCrmkjiSedTcJd66Gqz/F0u+3nBe1imeq\n/sLElefz9Su3cPH/vc6d733PvLW5VLi94Y5YKaUOEmzL20JgAvCnwLoRESvwR2B+M8QVekfQArZt\n/Xo8Hg+9evVqhoAazufzccIJJ/Daa68dtG1/q9r111/PueeeyyeffMK8efN4+OGH+etf/8q0adMa\nfL327dtz1VVXcdVVV3H//ffTrVs3nnjiCWbMmIHP52PMmDE8+OCDBx2nLW0q7EQgayiurKFw3t9g\n/Sekffs2N2z6Dzf6PuT71d3453cn82fLSfTr1olRPdP5Tfc0UmOjwh25UkoFnbzdCXwpIoOBKPyD\nFHoBCcBJzRSbaqABAwbw8ccfk56eTlxc3CH3y8rKYvLkyUyePJn77ruPF198kWnTpuFwOADwehve\n2pCamkqbNm0oKSmpjmXu3Ll07twZq9Va5zEOh6O6L55SYWN3Qe+LsfW+GIp3werZ9Fn1Nv12v8J9\n8gZLtvRn3vqe/MP0JL59b0b1ymBUj3S6psWGO3KlVCsV7Dxva4G+wDLgM8CJf7BCf2OM3gNrIcaP\nH09cXBxjxoxh0aJFbN68mS+//JKpU6eSnZ0NwI033shnn33G5s2b+fbbb/n888/p2bMnAJmZmTgc\nDubOncvu3bspKqr7gd/Tp0/nxhtvZN68eWzatInVq1dzyy238MsvvzBmzBgApk6dys6dO7niiiv4\n+uuv2bRpE5999hnXXHMNVVX+O/CdOnXi+++/55dffmHv3r14PDrjjAqzuAwYdhOWKUvhuoXYhkzk\nlLgd3G+fyWeOO/nHnsvpMG8yrz39Z65+5HUenLOWFZvz8fp0wINSKnSCnufNGLMTuLcZY1GNFB8f\nz+LFi/njH//IRRddRHFxMW3btmXkyJHVU3i43W6mTJlCTk4O8fHxjB49mieeeALwzxX35JNP8tBD\nD/GnP/2J0aNHM3fu3IOuM3ToUJYvX86kSZPYsWMHsbGxHHvssbz99tvVk+5mZWWxdOlSpk2bxujR\no6mqqiIrK4szzjijuiVuypQpLFmyhP79+1NaWsqyZcsYOnRoiH5aSh2GCGT2g8x+yJkPQUE2bFlM\n4pbFnLFpIecUr4DymeStiOerr7rzqK0P1s6n0Lf/EE4+No2YKH0MtFKq+cjhhsiLSDTwKDAG/+3S\nz4GbjTF7QxPekRs0aJD55ptv6ty2bt266jnNGmN9C+vzpppGU9WPprJgwQJGjBgR7jAabH/MCxYs\nCGscTc6Y6mTOvXEh7o2LiC7fAcBeE8/Xpge7kwdDx5Nof+zx9M1KoU1cy+8rF6n1TEWWSKxnofou\nE5GVxphBwexb35+H9wG/B94EKoErgL8DlzYqQqWUilQikNQJkjph7z8OeyCZ82xahO/HLzhx+1IS\nC5ZDwbOUrHLyo+nEfHs3ylL74uo0iI7detOnfRJxTnu4P4lSKkLVl7xdBFxjjJkFICJvAktExGqM\n0TH0SikVSOZsAzuRNvBKf9m+bCo3LaJ0wwo67fiO/kWf4sj9D+RC0Vcu1pjObHMeR2WbvsR2HkR6\npx7EOu1EO6y4HDai7VZcDitRNgu15tZUSql6k7cOwKL9K8aYFSLiAdoC25ozMKWUilhJHYka2JH0\ngeP8614P7F1PyeavKdq4gs47VzGo5GPsOf+CHChcFM1aXyfWmHS2mAy2mAw2m0y2kYbNEY3LYSXa\nYSU5xsGQzskM65LK4E5JRDu0b51SrVF9//KtHDw5ryeI45RSSu1ntUF6L2LTexE7dIK/zOvG7F7L\nvg0rqNr6LT3y1zGgeBVRVfuqDzMIRfY09kS1I9fWjg3l6Xy1JJ5FC1PZZUmja4f2DOuawrAuqRzf\nIRGHLdh515VSkay+JEyAN0Wk5mRcTuAlEal+xqkx5vzmCK45GWP0doQ6iD7jUoWM1Y5k9iM5s9+B\n5eUFkL8J8jcheRtJyN9IQt5GuuYv5qTyfYy3Uf3NXZIbw7YdKWz/sg2zJA1bchax6cdgTe6IM7UT\niSnptIlz0iYuCpej7vkWlVKRp77k7eCp+v2DFyKa3W6nvLyc6OjocIeiWpjy8nLsdu1IrsLIlQjt\nBviX2sryYd9mKNgGBVuJLdxG17wttN+7BUfxWqIKyqHg191LjJMck8pS04ZcSxpFURlUxLTDGp+B\nKymTuJRM0lLTyExyUeo2+ketUhHisMmbMeb3oQoklNLS0sjJyaFdu3a4XC79slIYYygvLycnJ4f0\n9PRwh6NU3aKT/Uu7gdVF9sCCMVC+D0/+VkpyN1G+ZzPe/GxiC7fRr2Q7MRVLcVUV+zvC7AP883ZT\naezsJZ4OJp7/LUwgXxIplAQKLIkUWZMosSVR7kjBFpOMKz6ZuNh4UuKcpMQ4SIl1kBIbVf1e++Ap\nFRqt8l9afHw8ADt27MDtdh/xeXbt2oUxBotF+5kcDex2O+np6dX1Q6mIIgLRydiik0lsfzyJde1T\nUehvtSvdja94NyX5OyjL34WvKJeo3VvoZa3AVfUjMZ59WI3H38PZA1QARcBOcBsrRURTaGIoIoY9\nJoF1JoE9JFBoScYXnUp6mzQ6pKfQuW0burRtQ5QrjjJ7AjtLYVdhBXuKK+maFkvPzHgsFv3jWamG\napXJG/gTuMb+Jz1lyhQKCgpYtWpVE0WllFLNyJkAGf6nrViA+MAC/glIj9s/eaoxUFEAJXugdA+U\n7vb3xasoxF5RSHzZPpwl+0gtzadL6W5s5dlEVe7Dgs+f6G3joPkIooE048Jq4nEST66JZYfVSVxc\nPClJCURFx1Mk8RRaEsgjgSpHEjHxicTFJRGfmMQx7dKJc7X8yY6VCoVWm7wppZQ6BBFwJfmXNsce\ntLn6Vm1NPi+U5UFJLlSWsK+wkC279pKzOw9vZQnptlLaSBEJvgLauPfhLsmjsjwPX/EvOIoqiaWC\njnL4OyFluPDYovE5YqkQF6W4KPFFUSYuqiwuKi3RVFqjcVv97z1WFz6LA5/FTpTTRUZSPOlJcTid\nLiqx4RU7bdu2I6VNW/9nPgxjDFvzy2gTF6W3h1XYhbwGisj1wB1AJvAj8AdjzKLD7N8HeBYYAuQD\nLwD3Gx0WqJRSLYfFCrFp/gVIApL6Qv96DjPGsCWvjJzyKhKsVSSYQmI9+/CW5FFSvI+y4kLKSwrI\nz8+noCCf0uJ9OCrLiKWCBFsl8ZYi2phynKYclynHRUWDQ6/EQaElEcGH3bipwME+E0epNR5XdDQO\nh5NtRV72loPPYiclIZbUxHgS42JxREVR4bOxtwKyCzx4xE7HtCRSEuKw2By4oqNJiI3F5ojC6nAR\nlZgJMWkUVHio8vpIjYnSW8eqwUKavInIZcDTwPXA4sDrf0WkpzFmax37x+N/nupCYDDQHXgVKAUe\nD1XcSimlmoeI0Dk1BogJlPgHDNnwP1A7pdb+Pp9hX1kVCS47Nmsd/Y19PnCXQmUJVJWCtwq8Vfg8\nVewtKGLXvmI87kocuLF4qyjM20n53q3YyveCxQZWBy6pIs5XSFJVIVXFhRhfFT1sPuJiDHgrobgS\nW5EbBx4s4m9H6AKcsD+GXfV/7mhjJQorpVjxYMMnNiw2O1jtYLFhLHZK3FDps2J3OKjwWbBY7cTH\nRlPiFtzGis1ux253UFgFMU4nXosND1YSYqLJTI5DrHY25VeSlhhHrCsKsdjYW+5l/a4SYmJiOP64\nrkj5Pv8IZ5sTjA/i24Ls/7mKf45Ciz3wswm8Bt4biw2xWP0/86oScMT6WzB9Hv9ijQLtE94sQt3y\ndisw0xjzUmD9JhE5E5gC3FXH/r/D31VivDGmHFgjIt2BW0XkCW19U0qp1sViEVJiD9P3zWKBqDj/\nUrMYSMuCtAZezxhDYbmbxGjHAeWF5W7W5BZTWl5BvN1HRqyFzBgrxlNBzt5C8ouK8XmqKC0ro7C4\nFPFWUlRczIZNG4n35tMnI5o2MRYqKqsw3irKKyopLCnDW+XGajzY8BJrN8TaDFVllbisbrzlZVQU\n52HHi128/v3ESzpebDUWO14QDxYMXWt9njaBBYBvG/jDqEUAH4IF/3/FPqwIPoRf/2v2ig0jVgwW\njMXGUGMoW+JALBasViteI4jFisViwYcFu82KxydUeEEsFuw2G16LA4zBig+rwwWOaOwOJwBuH1gt\nFtw+g91mBSN4jCHKZsWIIAiI4PERSPYlcIv84FefxYbFEeNP9sWCRQTcZf55F50JjfthNbGQJW8i\n4gAGAo/V2vQZMOwQh50ILAokbvt9CtwPdAI2N3GYSimlVDUROShxA0hw2RnUKfng/YH2SdD+EOer\ncHup9PhIcB16PskKt5fSSg/JMY4DprIqr/KycU8JndNicdqtFJRVsbekkk4pMWzbV47DZsFhtbBs\nWwHz1+WyaXcRZ/dqw7qcfOzi45edBUTZDA+N6c2Sddls2rKFIksCeXt30ylBqHD7yLQWkhbnZN3O\nIqJs0CXZSXFZOTl5xZRXVmAPJIgxduiY6GDb3kKiHHaKfE5c3mLEYqXUY8GLFadU4W8L9GHFhw0v\nFnzYAgmeP10zWMQg+9/jT9L2r1vx4aQKLxa82HFSRrTsw44HqwQm3AcEg9UCYkxgFgj/e4v4t3l9\nBquAiH+73QIWAZuAL3CM+NzEWqr8n9DnwyIGnzjwFe2iosrXwJrTvELZ8paK/3FbubXKc4FRhzgm\nA9hex/77tx2QvInIJGBSYLVERNYDCUBhPbHVt8/htqeKyN56zt8SBfNzaYnXasy5GnpsQ/ZvbD07\nbB0DIrGOASSIiNazptm/2b/LiMx6FqnfZY09X1DHzq5j/zdubvR5W2E9ywnFd1nHoPc0gYyzuRf8\nD7M3wCm1yu8F1h/imM+AV2qVZQXOc2KQ132xsfscbjvwTah+hk38+6j359ISr9WYczX02Ibs39h6\ndjTWsab+3YfyWi2xnul3WfP/3kN9La1nkbOEsp4Fs4SyJ+FewMv+3qi/SufQ3Tt3HWL//duC8Z8m\n2CeYc0SaUH6mprxWY87V0GMbsn9j69nRWMdA61lT7q/fZXWL1DrW2PNpPQutFvWZJJBRhuZiIsuB\n740xk2qU/Qy8b4w5aMCCiEwBHgHSjDEVgbI/ATcA7U0ogz8EEfnGGDMo3HGoo5fWMRUKWs9UKGg9\naxqhHsP7BDBBRCaKSA8ReRr/7dQZACLykIjMr7H/20AZMFNEeovIRcA0oCWNNH0x3AGoo57WMRUK\nWs9UKGg9awIhbXmD6kl678Q/Se8a4BZjzMLAtpnACGNMpxr79wGewz9J7z78id5fW1DyppRSSikV\nMiFP3pRSSiml1JHTqY+VUkoppSKIJm9KKaWUUhFEk7dmIiLnish6EflFRCaGOx51dBKRf4nIPhF5\nL9yxqKOTiHQQkQUislZEfhCRS8Mdkzq6iEiiiHwjIqtEZI2IXBvumFo67fPWDETEBqwFTgOK8D9B\nbqgxJi+sgamjjoiMAOLwP//3kjCHo45CIpIJpBtjVolIBrASONYYUxrm0NRRQkSsQJQxpkxEYvAP\nZhyk/2cemra8NY8hwI/GmBxjTDHwCXB6mGNSRyFjzAKgONxxqKOXMWanMWZV4P0u/BOuH/xQT6WO\nkDHGa4wpC6xGQeBxpeqQNHmrg4icIiIfiUiOiBgRmVDHPteLyGYRqRCRlSJyco3NbYGcGuvbgXbN\nHLaKME1Qz5SqV1PWMxEZCFiNMduaO24VOZqijgVunX6P///LvxljIvD5p6GjyVvdYvE3204Fymtv\nFJHLgKeBB4H+wFLgvyKSFcogVcTTeqZCoUnqmYgkA68Dk2qfQ7V6ja5jxpgCY0w/oDNwhYjUfjSm\nqkH7vNVDREqAG40xM2uULQd+MMZcW6PsF+A9Y8xdIjIMuMMYc2Fg21PACmPM26GNXkWKI6lnNcpG\nBI7VPm/qsI60nolIFPA58JIx5o3QRq0iSWO+y2psex74whijA7EOQVveGkhEHMBA4LNamz4DhgXe\nrwB6i0g7EYkFzgI+DV2UKtIFWc+UapRg6pmICDAT/3+mmripBgmyjqWLSFzgfQJwCrA+lHFGGk3e\nGi4VsAK5tcpzgQwAY4wHuA34H7AKeFxHzagGqreeAYjIPGA2cLaIbBeRE0MXojoKBFPPTgIuA8YE\npnJYFXhsoVLBCKaOdQQWBfq8LQKmG2NWhy7EyGMLdwBHK2PMR8BH4Y5DHd2MMaPCHYM6uhljFqN/\n6KtmZIxZARwf7jgiif6DbLi9gBeo3ZkyHdgV+nDUUUrrmQoFrWequWkdawaavDWQMaYK/ySVo2tt\nGo1/BI1Sjab1TIWC1jPV3LSONQ+9bVqHwCCDroFVC5AlIscD+caYrcATwBsisgJYAkzGP7fbjHDE\nqyKT1jMVClrPVHPTOhZ6OlVIHQJTL/yvjk2vGWMmBPa5HrgTyMQ/v80txpiFoYpRRT6tZyoUtJ6p\n5qZ1LPQ0eVNKKaWUiiDa500ppZRSKoJo8qaUUkopFUE0eVNKKaWUiiCavCmllFJKRRBN3pRSSiml\nIogmb0oppZRSEUSTN6WUUkqpCKLJm1JKhYCIGBG5JNxxKKUinyZvSqmjnojMDCRPtZevwh2bUko1\nlD7bVCnVWswDrqxVVhWOQJRSqjG05U0p1VpUGmN21VryofqW5o0iMkdEykQkW0TG1TxYRPqIyDwR\nKReR/EBrXkKtfcaLyGoRqRSRXBF5rVYMySIyW0RKRWRT7WsopVQwNHlTSim/+4CPgOOBF4HXRWQQ\ngIjEAJ8CJcAQ4EJgGPDK/oNF5DrgBeBVoA9wJvBDrWvcC3wI9APeBV4Rkazm+0hKqaORPpheKXXU\nE5GZwDigotam54wxfxQRA/zDGHNtjWPmAbuMMeNE5FrgMaC9MaY4sH0E8D+gmzFmg4hsB940xkw7\nRAwGeNgYc1dg3QYUAZOMMW824cdVSh3ltM+bUqq1WAhMqlVWUOP9slrblgHnBN73AH7Yn7gFLAV8\nQE8RKQLaAfPriaG6Jc4Y4xGRPUBacOErpZSfJm9KqdaizBizoRnO25DbF+46jtXuK0qpBtEvDaWU\n8htax/q6wPt1QB8RiauxfRj+79B1xpjdQA4wstmjVEq1etryppRqLaJEJKNWmdcYsyfw/iIR+RpY\nAFyCPxE7IbDtLfwDGl4XkXuBJPyDEz6o0Zr3APCkiOQCc4BoYKQx5vHm+kBKqdZJkzelVGsxCthZ\nqywHaB94//+Ai4FngD3A740xXwMYY8pE5AzgKWAF/oEPHwJT95/IGPN3EakCbgMeAfKBT5rrwyil\nWi8dbaqUavUCI0EvNca8F+5YlFKqPtrnTSmllFIqgmjyppRSSikVQfS2qVJKKaVUBNGWN6WUUkqp\nCKLJm1JKKaVUBNHkTSmllFIqgmjyppRSSikVQTR5U0oppZSKIJq8KaWUUkpFkP8PndlMbgUtuKQA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f170ade3400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.plot([x+1 for x,y in accuraciesTraining],[1-y for x,y in accuraciesTraining],label='Training Set')\n",
    "plt.plot([x+2 for x,y in accuraciesTest],[1-y for x,y in accuraciesTest],label='Test Set')\n",
    "\n",
    "plt.plot([1,1],[0.0001,2],c='black')\n",
    "#plt.plot([10,10],[0.0001,2],c='black')\n",
    "plt.plot([20,20],[0.0001,2],c='black')\n",
    "#plt.plot([500,500],[0.0001,2],c='black')\n",
    "plt.plot([2000,2000],[0.0001,2],c='black')\n",
    "\n",
    "#plt.xticks(np.linspace(0,100,21))\n",
    "\n",
    "plt.legend(loc='lower left',fontsize=14)\n",
    "\n",
    "#plt.grid()\n",
    "\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim([10**(-4),2])\n",
    "\n",
    "plt.xticks([1,10,100,1000],fontsize=14)\n",
    "plt.yticks([0,0.5,1],fontsize=14)\n",
    "\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "#plt.xlim([-10,2010])\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Percent Error',fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = [[0,-1]]\n",
    "idx = 0\n",
    "for i in range(2001):\n",
    "    if (i % 10 == 0) or (i < 10):\n",
    "        if (i % 100 == 0) or (i < 100):\n",
    "            idx += 1\n",
    "            counts.append([idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, -1],\n",
       " [1, 0],\n",
       " [2, 1],\n",
       " [3, 2],\n",
       " [4, 3],\n",
       " [5, 4],\n",
       " [6, 5],\n",
       " [7, 6],\n",
       " [8, 7],\n",
       " [9, 8],\n",
       " [10, 9],\n",
       " [11, 10],\n",
       " [12, 20],\n",
       " [13, 30],\n",
       " [14, 40],\n",
       " [15, 50],\n",
       " [16, 60],\n",
       " [17, 70],\n",
       " [18, 80],\n",
       " [19, 90],\n",
       " [20, 100],\n",
       " [21, 200],\n",
       " [22, 300],\n",
       " [23, 400],\n",
       " [24, 500],\n",
       " [25, 600],\n",
       " [26, 700],\n",
       " [27, 800],\n",
       " [28, 900],\n",
       " [29, 1000],\n",
       " [30, 1100],\n",
       " [31, 1200],\n",
       " [32, 1300],\n",
       " [33, 1400],\n",
       " [34, 1500],\n",
       " [35, 1600],\n",
       " [36, 1700],\n",
       " [37, 1800],\n",
       " [38, 1900],\n",
       " [39, 2000]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = np.array([[np.exp(x)/sum([np.exp(y) for y in prob]) for x in prob] for prob in probs_estimators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findProj(data,eigs=4):\n",
    "    data = np.array(data)\n",
    "    DDT = np.log(np.dot(data,data.T))\n",
    "    DDT_sums = np.array([sum(row)/len(data) for row in DDT])\n",
    "    DDT_sum_sums = sum(DDT_sums)/len(data)\n",
    "    DDT_PCA = np.array([[DDT[i][j] - DDT_sums[i] - DDT_sums[j] + DDT_sum_sums for i in range(len(data))] for j in range(len(data))])\n",
    "    \n",
    "    wR,vRt = splin.eigh(DDT_PCA,eigvals=(len(DDT)-1-eigs,len(DDT)-1))\n",
    "    wI,vIt = splin.eigh(DDT_PCA,eigvals=(0,eigs))\n",
    "    \n",
    "    W = list(wR)\n",
    "    W.extend(list(wI))\n",
    "    W = np.array(W)\n",
    "    sorting = abs(np.array(W)).argsort()[::-1]\n",
    "    \n",
    "    V = list(vRt.T)\n",
    "    V.extend(list(vIt.T))\n",
    "    V = np.array(V)\n",
    "    \n",
    "    W = W[sorting]\n",
    "    V = V[sorting]\n",
    "    \n",
    "    imCol = []\n",
    "    for i in range(len(W)):\n",
    "        if W[i] < 0:\n",
    "            imCol.append(i)\n",
    "            \n",
    "    proj = np.dot(V.T,np.diag(np.sqrt(np.abs(W))))\n",
    "    \n",
    "    return(proj,imCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj,imCol = findProj(np.sqrt(probs),eigs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveThing(proj,'proj.pckl')\n",
    "saveThing(probs,'probs.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['C'+str(i) for i in range(10)]\n",
    "clist = []\n",
    "labels = []\n",
    "for label in mnist.test.labels:\n",
    "    for e in range(10):\n",
    "        if label[e] == 1:\n",
    "            clist.append(colors[e])\n",
    "            labels.append(e)\n",
    "saveThing(labels,'labels.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3D plots\n",
    "px = proj[:,0]\n",
    "py = proj[:,1]\n",
    "pz = proj[:,2]\n",
    "\n",
    "mean_x = px.min()\n",
    "mean_y = py.min()\n",
    "mean_z = pz.min()\n",
    "\n",
    "Xdist = px.max() - px.min()\n",
    "Xcntr = (px.max() + px.min())/2.0\n",
    "Ydist = py.max() - py.min()\n",
    "Ycntr = (py.max() + py.min())/2.0\n",
    "Zdist = pz.max() - pz.min()\n",
    "Zcntr = (pz.max() + pz.min())/2.0\n",
    "\n",
    "dist = 0.5*max(Xdist,Ydist,Zdist)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.view_init(30,-60)\n",
    "\n",
    "listTemp = [i for i in range(len(proj))]\n",
    "\n",
    "ax.scatter(px,py,pz,c=clist,edgecolor='black',linewidth=0.2)\n",
    "\n",
    "ax.set_xlim([Xcntr - dist, Xcntr + dist])\n",
    "ax.set_ylim([Ycntr - dist, Ycntr + dist])\n",
    "ax.set_zlim([Zcntr - dist, Zcntr + dist])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "arrowSize=2*dist/5\n",
    "\n",
    "vects = [[mean_x+arrowSize,mean_y,mean_z],[mean_x,mean_y+arrowSize,mean_z],[mean_x,mean_y,mean_z+arrowSize]]\n",
    "\n",
    "for v in vects:\n",
    "    a = Arrow3D([mean_x,v[0]],[mean_y,v[1]],\n",
    "                [mean_z,v[2]],mutation_scale=20,\n",
    "                lw=3,arrowstyle=\"-|>\",color=\"r\")\n",
    "    ax.add_artist(a)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = -2*np.log(np.dot(probs,probs.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_embedded=TSNE(n_components=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleDigits = mnist.test.images[[3,2,1,30,19,15,21,0,61,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image in sampleDigits:\n",
    "    plt.imshow([image[28*i:28*(i+1)] for i in range(28)],cmap='Greys')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveThing(sampleDigits,'sampleDigits.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = openThing('probs.pckl')\n",
    "labels = openThing('labels.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def klDiv(p1,p2):\n",
    "    return sum(p1*np.log(p1)-p1*np.log(p2) + p2*np.log(p2)-p2*np.log(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances = [[-8*np.log(np.dot(np.sqrt(p1),np.sqrt(p2))) for p1 in probs] for p2 in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances = abs(np.array(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=3).fit_transform(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "klDistances = [[klDiv(p1,p2) for p1 in probs] for p2 in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_kl = TSNE(n_components=3).fit_transform(klDistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_kl2D = TSNE(n_components=2).fit_transform(klDistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_euclid = TSNE(n_components=3,init='pca').fit_transform(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3D plots\n",
    "proj = X_kl2D\n",
    "\n",
    "px = proj[:,0]\n",
    "py = proj[:,1]\n",
    "pz = proj[:,2]\n",
    "\n",
    "mean_x = px.min()\n",
    "mean_y = py.min()\n",
    "mean_z = pz.min()\n",
    "\n",
    "Xdist = px.max() - px.min()\n",
    "Xcntr = (px.max() + px.min())/2.0\n",
    "Ydist = py.max() - py.min()\n",
    "Ycntr = (py.max() + py.min())/2.0\n",
    "Zdist = pz.max() - pz.min()\n",
    "Zcntr = (pz.max() + pz.min())/2.0\n",
    "\n",
    "dist = 0.5*max(Xdist,Ydist,Zdist)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.view_init(30,-60)\n",
    "\n",
    "ax.scatter(px,py,pz,c=clist,edgecolor='black',linewidth=0.2)\n",
    "\n",
    "ax.set_xlim([Xcntr - dist, Xcntr + dist])\n",
    "ax.set_ylim([Ycntr - dist, Ycntr + dist])\n",
    "ax.set_zlim([Zcntr - dist, Zcntr + dist])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveThing(X_kl2D,'tsneKL2D.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X_kl2D[:,0],X_kl2D[:,1],c=clist,edgecolor='black',linewidth=0.2)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProjections(proj0,clist,gridsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProjections(proj12,clist,gridsize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProjections(proj49,clist,gridsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(proj1[:,1],proj1[:,2],c=clist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(proj12[:,1],proj12[:,2],c=clist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(proj0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
